{"./":{"url":"./","title":"ai学习篇","keywords":"","body":"Introduction 笔记跳转 要使用深度学习，至少要打败机器学习的传统算法。 参考： 学习视频：Python机器学习【全46集：一起啃书一起啃代码】｜Chenghsi Hsieh老师｜参考书作者Sebastian Raschka code：python-machine-learning-book-2nd-edition jupyter：vscode安装python插件自带jupyter(.ipynb) Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-09-04 12:19:00 "},"ml/chapter1/section1/":{"url":"ml/chapter1/section1/","title":"1.1 机器学习简介","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 机器学习分类 1.1 监督式学习 1.2 非监督式学习 1.3 强化学习 2 常用数据集--鸢尾花 机器学习简介 1 机器学习分类 1.监督式学习 2.非监督式学习 3.强化学习 监督式学习与非监督式学习的最大不同 前者给答案与反馈去训练算法，后者不给，由自己去找数据里隐藏的结构。 1.1 监督式学习 分为两类： 分类; 回归。 1.2 非监督式学习 分群 降维 1.3 强化学习 举例子，去面试，在经过考官一系列的问题后，在这个过程中，考官不给任何反馈，直到最后，考官会根据你的表现给出评分，如果成绩不好，就要自己反思到底是过程的哪一步没做好。（大概像是这样的操作） 2 常用数据集--鸢尾花 样本：sample 特征：feature 反馈：label Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-09-04 12:59:56 "},"ml/chapter1/section2/":{"url":"ml/chapter1/section2/","title":"1.2 手撸感知机（perceptron）","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 分类算法简介 2 感知机原理--二元分类 2.1 线性函数定义 2.2 怎么估计W 2.3 权重更新的原理 3 python代码实现 感知机（perceptron） 手撸基本算法，避免以后只会直接调用第三方模块的懵逼状态。 1 分类算法简介 多元分类：可以区分超过两种种类不同的样本，如，三种，四种不同的样本。 方法分为1v1或1vAll，但是本质上还是都利用的二元分类的方法。 1v1：从有n个种类的数据中抽取两种不同的样本，一共做C_n^2次分类； 1vAll：从有n个种类的数据中抽取两种来使用二元分类，第1种是随便抽取1种，然后剩下除已经抽了的一种外的其余n-1为第2种，按照次序一共做n次分类。 2 感知机原理--二元分类 感知机属于监督式算法和朴素贝叶斯算法。 现在这个算法说白了就是，假如我们有一个公式：y = k * x + b，一条简直的直线， 我们已知： y：答案/label x：样本的特征/feature 想求： k：权重/weight b：截距/梯度 因为我们有多组(x,y)，通过代入公式，不停地去计算一个符合大多数情况下，x到y的映射的估计值k和b。 之后再代入一个新的x，就能得出一个符合之前训练情况下的y值了。 2.1 线性函数定义 这是一个简单的二元分类 （指只能区分两种种类不同的样本）算法，规定数据必须线性可分，否则训练时无法停下来，该算法希望在一堆数据里面找到一条直线能使其被分成2类。 该直线定义为Z： Z = w1x1 + w2x2 + w3x3 + w4x4 + … + wnxn 人为规定： φ(Z) = 1, if Z >= θ φ(Z) = -1, otherwise x1,x2,x3…xn为样本的各个特征， w1,w2,w3…wn为各个特征所对应的权重值：要估计的参数。 φ(Z)就是label答案 θ：人为规定的一个阈值 但是θ到底要设多少，有些麻烦，我们也不知道值设为多少合适，于是通过如下变换： 因为 Z = w1x1 + w2x2 + w3x3 + w4x4 + … + wnxn 所以如果 Z >= θ 即 w1x1 + w2x2 + w3x3 + w4x4 + … + wnxn >= θ 将θ移到左边 w1x1 + w2x2 + w3x3 + w4x4 + … + wnxn - θ >= 0 此时令新的Z = w1x1 + w2x2 + w3x3 + w4x4 + … + wnxn - θ 即 Z >= 0 便可将θ的值也交给程序去估计， 此时，这个-θ其实就是截距，为了统一，将-θ改成w0x0，其中x0其实就等于1，而w0则是-θ. 则新的定义式与判断条件则变为以下： Z = w0x0 + w1x1 + w2x2 + w3x3 + w4x4 + … + wnxn. φ(Z) = 1, if Z >= 0 φ(Z) = -1, otherwise 这里提醒一下，有关二分类φ(Z)到底是分为1和0，还是1或-1，是由算法决定来的，由感知机原理可知，分成1和-1可以成功估计出权重。 为了书写方便，Z的定义用向量(默认列向量)表示： Z = W^T * X # 左转右不转是为数，即 Z 为一个数值 分类预测期待展示结果： 2.2 怎么估计W Ⅰ：初始化W 现在我们在某个时间点t，取出第n组样本，计算Z的值： Z_n(t) = W_t^T * X_n(t) 那么首先得初始化对应该样本中每个特征的权重w，可以全部初始化为0，但基本上是将权重值初始化为0附近的随机数。 Ⅱ：估计W与权重更新 此时有如下判断公式： sign( W_t^T * X_n(t) ) == y_n(t) ? sign()：取计算结果的正负号 y_n(t)：label(答案) 将某样本的特征（向量）与权重（向量）做内积后，再由上面的判断式来区分到底该样本属于哪一类，如果判断式判断不一样，则要更新权重，否则不更新。 在二分类问题中，并且是在该感知机算法中，标签仅为1或-1，上述算法可由公式描述为： 如果 sign( W_t^T * X_n(t) ) ≠ y_n(t) (1) 则 W_(t+1) = W_t + y_n(t) * X_n(t) (2) 否则不更新权重。 其中t表示某一次的计算，n表示某一个样本，sign()其实就是φ(Z)。其中要注意权重的更新公式(2)，W为向量，即每次更新都要更新所有特征所对应的权重值。 Ⅲ：权重更新公式第2种写法 (2)的权重更新公式： W_(t+1) = W_t + ∆W_t ∆W_t = y_n * X_n(t) (2) 可改写为(3)： W_(t+1) = W_t + ∆W_t ∆W_t = η * [ y(n) - y'(n) ] * X_n(t) (3) # 其中`η`为学习速率。y'(n)是上一轮sign()的结果 (3)与(2)其实本质上是一样的，除开学习速率η是新增加的，(3)相比(2)只不过替换了y_n(t)的写法，可以通过举例来说明： 假如估计出的判断值为-1，而实际上标签值为1，那么： (2)式为∆W_t = 1 * X_n(t), (3)式为∆W_t = [1 - (-1)] * X_n(t) = 2 * X_n(t)， 实际上只是更新变更快了，最终的概念是一样的。 2.3 权重更新的原理 至于为何权重的更新如公式(2)所示，可以这样解释： 和上面的例子一样，如果判断出为-1，而实际上为+1，而根据判断式： φ(Z) = 1, if Z >= 0 φ(Z) = -1, otherwise 其中的判断条件Z为两个向量的数量积，由余弦公式可知： cos(θ) = ( W^T * X ) / ( || W^T || ∙ || X || ) , 0 现在的情况是φ(Z) = -1， 通过判断式可知Z , 再通过余弦公式可知cosθ ，即90 . 最终推出两个向量的夹角为钝角（红色向量的夹角）， 此时通过权重更新公式(2)： W = W^T + 1 * X 由数值的方式，可以得到一条新的向量： 原来的权重向量加上真实的标签值1乘以特征向量，可得到新的权重W_(t+1)。 该特征向量与矩阵的特征向量不同，注意区分，此处只是刚好名字是这个。 再通过图的形式：由向量相加的平行四边形法则可知，新的向量为上图中绿色的向量，其与特征向量的夹角变小了， 也就意味着两条向量的数量积Z将变大：从Z小于0往Z大于0的方向移动（由负到正不是变大是什么） 而一旦Z大于0，那么判断出的φ(Z)就和正确的label值1一样了)，而从趋势上来看，将会把φ(Z)的值朝着正确的label值靠拢。 3 python代码实现 import numpy as np class Perceptron(object): \"\"\"Perceptron classifier. Parameters ------------ eta : float Learning rate (between 0.0 and 1.0) n_iter : int Passes over the training dataset. random_state : int Random number generator seed for random weight initialization. Attributes ----------- w_ : 1d-array Weights after fitting. errors_ : list Number of misclassifications (updates) in each epoch. \"\"\" def __init__(self, eta=0.01, n_iter=50, random_state=1): self.eta = eta self.n_iter = n_iter self.random_state = random_state def fit(self, X, y): \"\"\"Fit training data. Parameters ---------- X : {array-like}, shape = [n_samples, n_features] Training vectors, where n_samples is the number of samples and n_features is the number of features. y : array-like, shape = [n_samples] Target values. Returns ------- self : object \"\"\" rgen = np.random.RandomState(self.random_state) self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1]) self.errors_ = [] for _ in range(self.n_iter): errors = 0 for xi, target in zip(X, y): update = self.eta * (target - self.predict(xi)) self.w_[1:] += update * xi self.w_[0] += update errors += int(update != 0.0) self.errors_.append(errors) return self def net_input(self, X): \"\"\"Calculate net input\"\"\" return np.dot(X, self.w_[1:]) + self.w_[0] def predict(self, X): \"\"\"Return class label after unit step\"\"\" return np.where(self.net_input(X) >= 0.0, 1, -1) Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-09-04 18:06:23 "},"ml/chapter1/section3/":{"url":"ml/chapter1/section3/","title":"1.3 适应性线性神经元（Adaptive linear neurons）","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 梯度下降原理 损失函数 python代码实现 2. 适应性线性神经元（Adaptive linear neurons） 该分类器和感知机最大的不同是，该分类器引进了新的概念： 损失函数 梯度下降法 并且该分类器在训练W（向量）的时候，是一次性丢很多个样本（n），比如说丢100个样本，通过计算每个样本的Z，然后再经过激活函数的转换，得到最终的估计值（判断值）。 之前说过引进了一个新的概念：损失函数。 我们知道代价函数的英文是cost function，损失函数 的英文是loss function ，这两个单词都不是以字母J 开头的, 那为什么代价函数习惯用 J 表示呢？ 这个问题众说纷纭，流传广泛的说法是J 代表雅克比矩阵(Jacobian Matrix)，雅克比矩阵是所有方向上的导数组成的矩阵，最开始有人使用了它于是大家为了一致就一直使用J 了 而在该分类器中，它的损失函数J 定义为（形似最小平方法），估计值与标签值的差的平分，然后再累加起来所有的样本，公式表示为： 通过梯度下降法训练调整W，使得损失函数J在之后的计算中能够不停地变小，即最小化损失函数的值，当J达到最小的时候，也就意味着，训练后的W在计算这100个样本时，能够很好地与真实的标签值吻合，也就完成了训练的意义。 上一章的感知机则是一个样本一个样本地测试，来调整W的值。 梯度下降原理 由上图，可以看见J其实是关于W的函数，注意W是一个向量，里面包含（w0,w1…wn），对应有多少个特征。 而上图其实是一个简略版的图例，我们现在可以想象成W就是一个变量，一个值，那么假设现在J(W)的值位于图中黑球处，为了让J的值变小，如图中箭头方向，必须让W的值进行改变，那么改变的幅度∆w为： W_(j+1)=W_j+∆w ① 新的W等于旧的W加上变化的幅度 ∆w=-η*(dJ/dW) ② dJ/dw在上图表示黑球处的斜率。斜率的大小在此处有什么意义我不清楚，但是它的正负值的作用却在这里说的通。 举例说明，当J有关W的函数位于图中黑球处时，此时的斜率为正，而η一直为正（学习速率），再加上前面的负号，整个∆w便变成了负数，从图中看来，刚好可以让W朝着曲线的凹处变小，从而让J值变小。 反过来说，当J有关W的函数位于图中凹线左侧时，斜率为负，η为正，加上前面的负号，则负负得正，W同样朝着曲线的凹处变大，从而让J值变小。 回过头来，实际上W是一个向量，所以此处该对其中的每个权重值求偏微分，然后得出的变化幅度再去加上W向量中所对应的那个权重，进而改变每一个不同的权重值。 所以公式②变为： W_j=W_j+∆w ③ W向量中某个权重(W_j)加上对应的变化幅度得到新的W_j ∆w=-η*(∂J/∂W_j) ④ 注意③④这里的j和①②的j意思不同。 损失函数 由之前的定义，我们知道损失函数是有关W的函数，而为了使损失函数的值达到最小，我们通过梯度下降法来改变W的值，而其中幅度的变化使用到了偏微分，如④所示。如果我们定义损失函数为： 那么在对W求偏微分的时候，会发现二次方会放下来，而之后的运算会始终要多乘一个2，显得比较麻烦，于是为了方便，可以改变损失函数的定义，事先在前面乘以一个1/2，用来抵消掉微分后的2，即新的损失函数的定义式为： 那么对某个特征对应的权重进行偏微分后的式子如下所示： 而某个特征对应的权重的变化幅度为： python代码实现 class AdalineGD(object): \"\"\"ADAptive LInear NEuron classifier. Parameters ------------ eta : float Learning rate (between 0.0 and 1.0) n_iter : int Passes over the training dataset. random_state : int Random number generator seed for random weight initialization. Attributes ----------- w_ : 1d-array Weights after fitting. cost_ : list Sum-of-squares cost function value in each epoch. \"\"\" def __init__(self, eta=0.01, n_iter=50, random_state=1): self.eta = eta self.n_iter = n_iter self.random_state = random_state def fit(self, X, y): \"\"\" Fit training data. Parameters ---------- X : {array-like}, shape = [n_examples, n_features] Training vectors, where n_examples is the number of examples and n_features is the number of features. y : array-like, shape = [n_examples] Target values. Returns ------- self : object \"\"\" rgen = np.random.RandomState(self.random_state) self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1]) self.cost_ = [] for i in range(self.n_iter): net_input = self.net_input(X) output = self.activation(net_input) errors = (y - output) self.w_[1:] += self.eta * X.T.dot(errors) self.w_[0] += self.eta * errors.sum() cost = (errors**2).sum() / 2.0 self.cost_.append(cost) return self def net_input(self, X): \"\"\"Calculate net input\"\"\" return np.dot(X, self.w_[1:]) + self.w_[0] def activation(self, X): \"\"\"Compute linear activation\"\"\" return X def predict(self, X): \"\"\"Return class label after unit step\"\"\" return np.where(self.activation(self.net_input(X)) >= 0.0, 1, -1) Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-09-04 11:40:37 "},"ml/chapter1/section4/":{"url":"ml/chapter1/section4/","title":"1.4 通过标准化特征值来优化梯度下降","keywords":"","body":"3. 通过标准化特征值来优化梯度下降 为什么要对特征值进行标准化呢？ 举例，假如A样本的某个特征的数值为1，而B样本的这个特征值却为1000，两个样本的同一特征值相差太远，会造成在使用梯度下降，在调整该特征对应的权重时，变化过于剧烈，从而影响到整个公式的各个权重值。（我也不清楚这个理解到底是不是对的） 标准化定义，由某特征值减去该特征所属集合的期望，再除以该集合的标准差。这样可以使得各个样本的某特征值相差不是太远。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-09-04 11:40:37 "}}